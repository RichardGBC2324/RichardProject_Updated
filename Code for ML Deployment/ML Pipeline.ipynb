{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651853ce-aabf-475f-9e56-b5bba705f818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-storage\n",
      "  Using cached google_cloud_storage-3.0.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Using cached google_cloud_aiplatform-1.80.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting google-auth<3.0dev,>=2.26.1 (from google-cloud-storage)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage)\n",
      "  Using cached google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage)\n",
      "  Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage)\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from google-cloud-storage) (2.32.3)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage)\n",
      "  Using cached google_crc32c-1.6.0-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform)\n",
      "  Using cached proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from google-cloud-aiplatform) (4.25.3)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Collecting google-cloud-storage\n",
      "  Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Using cached google_cloud_bigquery-3.29.0-py2.py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Using cached google_cloud_resource_manager-1.14.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform)\n",
      "  Using cached shapely-2.0.7-cp312-cp312-win_amd64.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\richa\\newanaconda\\lib\\site-packages (from google-cloud-aiplatform) (4.11.0)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage)\n",
      "  Using cached googleapis_common_protos-1.67.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.68.1)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
      "  Using cached grpc_google_iam_v1-0.14.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.12.14)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-aiplatform)\n",
      "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached grpcio-1.70.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\richa\\newanaconda\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Using cached google_cloud_aiplatform-1.80.0-py2.py3-none-any.whl (7.1 MB)\n",
      "Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached google_cloud_bigquery-3.29.0-py2.py3-none-any.whl (244 kB)\n",
      "Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Using cached google_cloud_resource_manager-1.14.0-py2.py3-none-any.whl (384 kB)\n",
      "Using cached google_crc32c-1.6.0-cp312-cp312-win_amd64.whl (33 kB)\n",
      "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Using cached proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "Using cached shapely-2.0.7-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "Using cached googleapis_common_protos-1.67.0-py2.py3-none-any.whl (164 kB)\n",
      "Using cached grpc_google_iam_v1-0.14.0-py2.py3-none-any.whl (27 kB)\n",
      "Using cached grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached grpcio-1.70.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: shapely, rsa, protobuf, grpcio, google-crc32c, docstring-parser, proto-plus, googleapis-common-protos, google-resumable-media, google-auth, grpcio-status, google-api-core, grpc-google-iam-v1, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.68.1\n",
      "    Uninstalling grpcio-1.68.1:\n",
      "      Successfully uninstalled grpcio-1.68.1\n",
      "Successfully installed docstring-parser-0.16 google-api-core-2.24.1 google-auth-2.38.0 google-cloud-aiplatform-1.80.0 google-cloud-bigquery-3.29.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.14.0 google-cloud-storage-2.19.0 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.67.0 grpc-google-iam-v1-0.14.0 grpcio-1.70.0 grpcio-status-1.70.0 proto-plus-1.26.0 protobuf-5.29.3 rsa-4.9 shapely-2.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eeb7d2-1757-4c75-92a0-8215d66328bb",
   "metadata": {},
   "source": [
    "# Create Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08256d95-d919-4892-a3fd-0eb4d58e1baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful. Buckets: ['ml_ai_capstone_stock']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the path to your service account key JSON file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"capstone-ml-451002-bef2906dcf92.json\"\n",
    "\n",
    "# Test authentication\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "buckets = list(client.list_buckets())\n",
    "print(\"Authentication successful. Buckets:\", [b.name for b in buckets])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32799ae-13e2-49a5-b2db-5305cd00e699",
   "metadata": {},
   "source": [
    "# Upload Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f2a3fb-b05c-4a7c-9cf5-3b4e2617af09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created empty folder gs://ml_ai_capstone_stock/models/ml_model/assets/\n",
      "Created empty folder gs://ml_ai_capstone_stock/models/ml_model/variables/\n",
      "Uploaded ml_model/fingerprint.pb to gs://ml_ai_capstone_stock/models/ml_model/fingerprint.pb\n",
      "Uploaded ml_model/saved_model.pb to gs://ml_ai_capstone_stock/models/ml_model/saved_model.pb\n",
      "Uploaded ml_model/variables\\variables.data-00000-of-00001 to gs://ml_ai_capstone_stock/models/ml_model/variables/variables.data-00000-of-00001\n",
      "Uploaded ml_model/variables\\variables.index to gs://ml_ai_capstone_stock/models/ml_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "bucket_name = \"ml_ai_capstone_stock\"\n",
    "model_path = \"ml_model/\"  # The converted model directory\n",
    "destination_blob_name = \"models/ml_model/\"  # Cloud Storage path\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(bucket_name)\n",
    "\n",
    "# Upload the entire SavedModel directory, including empty folders\n",
    "for root, dirs, files in os.walk(model_path):\n",
    "    # Ensure empty directories (like assets/ and variables/) are created in GCS\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        relative_dir_path = os.path.relpath(dir_path, model_path).replace(\"\\\\\", \"/\") + \"/\"  # Convert to GCS-compatible path\n",
    "        blob_path = os.path.join(destination_blob_name, relative_dir_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "        # Create an empty blob to represent the folder in GCS\n",
    "        blob = bucket.blob(blob_path)\n",
    "        blob.upload_from_string(\"\")  # Upload an empty string to create the folder\n",
    "\n",
    "        print(f\"Created empty folder gs://{bucket_name}/{blob_path}\")\n",
    "\n",
    "    # Upload all files in the current directory\n",
    "    for file in files:\n",
    "        local_path = os.path.join(root, file)\n",
    "        relative_path = os.path.relpath(local_path, model_path).replace(\"\\\\\", \"/\")  # Normalize path for GCS\n",
    "        blob_path = os.path.join(destination_blob_name, relative_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "        # Upload the file to GCS\n",
    "        blob = bucket.blob(blob_path)\n",
    "        blob.upload_from_filename(local_path)\n",
    "\n",
    "        print(f\"Uploaded {local_path} to gs://{bucket_name}/{blob_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f77981-d0ce-4169-b7d0-6ec600ea12bb",
   "metadata": {},
   "source": [
    "# Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a40dd6e-5669-4c86-a627-1a4ffff1692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/1054820045782/locations/us-central1/models/9046092279550312448/operations/4505490684291055616\n",
      "Model created. Resource name: projects/1054820045782/locations/us-central1/models/9046092279550312448@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1054820045782/locations/us-central1/models/9046092279550312448@1')\n",
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/1054820045782/locations/us-central1/endpoints/892267979591385088/operations/1588284025661816832\n",
      "Endpoint created. Resource name: projects/1054820045782/locations/us-central1/endpoints/892267979591385088\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/1054820045782/locations/us-central1/endpoints/892267979591385088')\n",
      "Deploying model to Endpoint : projects/1054820045782/locations/us-central1/endpoints/892267979591385088\n",
      "Deploy Endpoint model backing LRO: projects/1054820045782/locations/us-central1/endpoints/892267979591385088/operations/352045927948615680\n",
      "Endpoint model deployed. Resource name: projects/1054820045782/locations/us-central1/endpoints/892267979591385088\n",
      "Model deployed at: projects/1054820045782/locations/us-central1/endpoints/892267979591385088\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=\"capstone-ml-451002\", location=\"us-central1\")\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=\"stock_prediction_model\",\n",
    "    artifact_uri=f\"gs://ml_ai_capstone_stock/models/ml_model/\",\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\",\n",
    ")\n",
    "\n",
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")\n",
    "print(f\"Model deployed at: {endpoint.resource_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad7c33d-f733-4bff-b445-4d05817431e5",
   "metadata": {},
   "source": [
    "# Convert to Actual Value (Unnormalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "be437299-d9a1-46b2-9af3-da57546082aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "Google_stock = pd.read_csv(\"GOOG.csv\")\n",
    "Google_stock['date'] = pd.to_datetime(Google_stock['date'])\n",
    "Google_stock['date'] = Google_stock['date'].dt.strftime('%d-%m-%Y')\n",
    "Google_stock['date'] = pd.to_datetime(Google_stock['date'], dayfirst=True)\n",
    "## Remove symbol column\n",
    "Google_stock.drop(columns=\"symbol\",axis=1,inplace=True)\n",
    "## Feature selection and set date as index\n",
    "df = Google_stock.loc[:,[\"date\",\"close\",\"high\",\"low\",\"open\",\"volume\"]]\n",
    "df=df.set_index(\"date\")\n",
    "# choose close as relevant attributes\n",
    "train_set = df.iloc[:,:4]\n",
    "# standardize using Min-Max Scaler\n",
    "Scaler = MinMaxScaler()\n",
    "Scaler.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad8cd5-e49c-4d2a-9a9c-dfc52e885498",
   "metadata": {},
   "source": [
    "# Validating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1fbccfb5-d9d9-4f1e-ba82-e25bd6625d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         close         high          low         open\n",
      "0  1546.435520  1550.478605  1516.304328  1534.378556\n",
      "1  1521.698605  1547.123358  1486.754352  1523.690448\n",
      "2  1354.673638  1375.727700  1309.667069  1334.545637\n",
      "3  1385.304004  1378.875393  1338.506873  1368.291365\n",
      "4  1537.969223  1571.047744  1506.246597  1547.517605\n",
      "5  1433.893486  1431.586182  1420.518347  1435.479712\n",
      "6  1591.770127  1632.987977  1562.037794  1612.180755\n",
      "7  1561.386326  1618.044743  1530.531594  1567.473205\n",
      "8  1554.418025  1603.027331  1528.139401  1564.189631\n",
      "9  1244.818399  1277.114173  1213.520807  1238.310504\n"
     ]
    }
   ],
   "source": [
    "# Generate test sequence \n",
    "test_set = np.random.rand(10,60,4)  # 60 time steps, 4 features each\n",
    "\n",
    "# To verify the result from the endpoint, first validate the result from the saved model\n",
    "reloaded_artifact = tf.saved_model.load(\"ml_model\")\n",
    "predictions = reloaded_artifact.serve(test_set)\n",
    "#print(predictions)\n",
    "\n",
    "# Unnormalize the predictions\n",
    "unnormalized_predictions = Scaler.inverse_transform(predictions)\n",
    "unnormalized_predictions = pd.DataFrame(unnormalized_predictions,columns=['close','high','low','open'])\n",
    "\n",
    "# Print the unnormalized values\n",
    "print(unnormalized_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00760b11-5d69-4e65-84e6-6f5b002b228f",
   "metadata": {},
   "source": [
    "# Send Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1e38c26c-f78c-4f55-a084-4cc08a915e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         close         high          low         open\n",
      "0  1546.435506  1550.478605  1516.304383  1534.378557\n",
      "1  1521.698604  1547.123469  1486.754408  1523.690448\n",
      "2  1354.673694  1375.727755  1309.667069  1334.545638\n",
      "3  1385.304115  1378.875448  1338.506873  1368.291420\n",
      "4  1537.969278  1571.047854  1506.246597  1547.517716\n",
      "5  1433.893541  1431.586237  1420.518347  1435.479711\n",
      "6  1591.770128  1632.987977  1562.037740  1612.180755\n",
      "7  1561.386399  1618.044853  1530.531538  1567.473205\n",
      "8  1554.418080  1603.027441  1528.139456  1564.189740\n",
      "9  1244.818398  1277.114062  1213.520807  1238.310449\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import google.auth\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Path to your downloaded service account JSON key\n",
    "SERVICE_ACCOUNT_FILE = \"capstone-ml-451002-bef2906dcf92.json\"\n",
    "\n",
    "# Authenticate and get an OAuth 2 token\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_FILE,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "auth_request = Request()\n",
    "credentials.refresh(auth_request)\n",
    "access_token = credentials.token\n",
    "endpoint_url = f\"https://us-central1-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict\"\n",
    "#  Column attributes for reference\n",
    "COLUMNS = ['close','high','low','open']\n",
    "# Use the testing set defined from the previous cell and convert to list\n",
    "instance = test_set.tolist()  # 60 time steps, 4 features each\n",
    "data = {\"instances\": instance}  # Wrap in an outer list for batch processing\n",
    "# Set Authorization header with Bearer Token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "# Send the request and handle errors\n",
    "try:\n",
    "    response = requests.post(endpoint_url, json=data, headers=headers)\n",
    "    response.raise_for_status()  # Raises an error for bad status codes\n",
    "    predictions = np.array(response.json().get(\"predictions\", []))  # Extract predictions\n",
    "    # Unnormalize the predictions\n",
    "    unnormalized_predictions = Scaler.inverse_transform(predictions)\n",
    "    # Print unnormalized predictions\n",
    "    df = pd.DataFrame(unnormalized_predictions, columns=COLUMNS)\n",
    "    df = df[COLUMNS]\n",
    "    print(df)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n",
    "    print(response.text if response is not None else \"No response received\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
